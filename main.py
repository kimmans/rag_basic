from dotenv import load_dotenv
load_dotenv()

import nest_asyncio
nest_asyncio.apply()

# í™˜ê²½ë³€ìˆ˜ í™•ì¸
import os

from llama_cloud_services import LlamaParse
import json

parser = LlamaParse(
    result_type="markdown",  # "markdown" ë˜ëŠ” "text" ì„ íƒ ê°€ëŠ¥
    language="ko",           # ì–¸ì–´ ì„¤ì •
    parse_mode="parse_page_with_lvm",  # íŒŒì‹± ëª¨ë“œ ì„ íƒ
    # ì¶”ê°€ ì˜µì…˜:
    # disable_image_extraction=False,  # ì´ë¯¸ì§€ ì¶”ì¶œ ë¹„í™œì„±í™” ì˜µì…˜
    # disable_ocr=False,               # OCR ë¹„í™œì„±í™” ì˜µì…˜
    vendor_multimodal_model_name="openai-gpt4o"  # LVM ëª¨ë¸ì„ Geminië¡œ ë³€ê²½
)

# íŒŒì‹±í•  ë¬¸ì„œ ê²½ë¡œ ì„¤ì •
paper_path = "data/CVM_articles.pdf"
data_dir = "data"

print(f"ğŸ“„ PDF íŒŒì¼ íŒŒì‹± ì‹œì‘: {paper_path}")

# ë¬¸ì„œ íŒŒì‹± ë° ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
md_json_objs = parser.get_json_result(paper_path)
json_dicts = md_json_objs[0]["pages"]

print("âœ… PDF íŒŒì‹± ì™„ë£Œ!")

# ê²°ê³¼ í™•ì¸ ë° ì¶œë ¥
if json_dicts:
    print(f"\nğŸ“Š íŒŒì‹± ê²°ê³¼:")
    print(f"  - ì´ í˜ì´ì§€ ìˆ˜: {len(json_dicts)}")
    
    # ì²« ë²ˆì§¸ í˜ì´ì§€ ê²°ê³¼ í™•ì¸
    first_page = json_dicts[0]
    print(f"\nğŸ“„ ì²« ë²ˆì§¸ í˜ì´ì§€ ì •ë³´:")
    print(f"  - í˜ì´ì§€ ë²ˆí˜¸: {first_page.get('page_number', 'N/A')}")
    
    # ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
    if "md" in first_page:
        md_text = first_page["md"]
        print(f"  - ë§ˆí¬ë‹¤ìš´ ê¸¸ì´: {len(md_text)} ë¬¸ì")
        preview_text = md_text[:500] + "..." if len(md_text) > 500 else md_text
        print(f"  - ë§ˆí¬ë‹¤ìš´ ë¯¸ë¦¬ë³´ê¸°:")
        print("=" * 60)
        print(preview_text)
        print("=" * 60)
    
    # ë¸”ë¡ ì •ë³´
    blocks = first_page.get('blocks', [])
    if blocks:
        print(f"\nğŸ“‹ ë¸”ë¡ ì •ë³´ (ì²˜ìŒ 3ê°œ):")
        for i, block in enumerate(blocks[:3]):
            print(f"  ë¸”ë¡ {i+1}: {block.get('type', 'unknown')} - {block.get('text', '')[:100]}...")
    
    # JSON ê²°ê³¼ ì €ì¥
    with open("parsed_result.json", "w", encoding="utf-8") as f:
        json.dump(md_json_objs, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ JSON ê²°ê³¼ê°€ 'parsed_result.json' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ë§ˆí¬ë‹¤ìš´ ê²°ê³¼ ì €ì¥
    markdown_content = ""
    for page in json_dicts:
        if "md" in page:
            page_num = page.get('page', 'N/A')
            markdown_content += f"# í˜ì´ì§€ {page_num}\n\n"
            markdown_content += page["md"] + "\n\n"
            markdown_content += "---\n\n"
    
    with open("parsed_result.md", "w", encoding="utf-8") as f:
        f.write(markdown_content)
    print(f"ğŸ’¾ ë§ˆí¬ë‹¤ìš´ ê²°ê³¼ê°€ 'parsed_result.md' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # í†µê³„
    total_text = ""
    for page in json_dicts:
        if "md" in page:
            total_text += page["md"] + "\n"
    
    print(f"\nğŸ“Š í†µê³„:")
    print(f"  - ì´ í˜ì´ì§€ ìˆ˜: {len(json_dicts)}")
    print(f"  - ì´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(total_text)} ë¬¸ì")
    print(f"  - ë‹¨ì–´ ìˆ˜: {len(total_text.split())}")
    
else:
    print("âŒ íŒŒì‹± ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")