from dotenv import load_dotenv
load_dotenv()

import nest_asyncio
nest_asyncio.apply()

# í™˜ê²½ë³€ìˆ˜ í™•ì¸
import os
import glob
from pathlib import Path
import time
import base64
from PIL import Image
from io import BytesIO
import requests
import json

# Docling ê´€ë ¨ import
from docling.document_converter import DocumentConverter
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import PdfPipelineOptions
from docling.document_converter import PdfFormatOption

def extract_images_from_pdf(pdf_path, output_dir):
    """PDFì—ì„œ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•˜ì—¬ í´ë”ì— ì €ì¥"""
    
    print(f"   ğŸ–¼ï¸ ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘...")
    
    # ì´ë¯¸ì§€ ì¶”ì¶œì„ ìœ„í•œ íŒŒì´í”„ë¼ì¸ ì˜µì…˜ ì„¤ì •
    pipeline_options = PdfPipelineOptions()
    pipeline_options.generate_picture_images = True
    pipeline_options.generate_page_images = True
    pipeline_options.do_table_structure = True
    pipeline_options.images_scale = 2.0
    
    # ë³€í™˜ê¸° ì„¤ì •
    converter = DocumentConverter(
        format_options={
            InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
        }
    )
    
    # PDF ë³€í™˜
    result = converter.convert(pdf_path)
    
    # ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„± (parents=Trueë¡œ ì¤‘ì²© ë””ë ‰í† ë¦¬ ìƒì„±)
    images_dir = output_dir / "images"
    images_dir.mkdir(parents=True, exist_ok=True)
    
    saved_images = []
    
    # ì´ë¯¸ì§€ ì¶”ì¶œ ë° ì €ì¥
    for idx, picture in enumerate(result.document.pictures):
        try:
            # base64 ë°ì´í„° ì¶”ì¶œ
            uri_str = str(picture.image.uri)
            if ',' in uri_str:
                base64_data = uri_str.split(',')[1]
                
                # ë””ì½”ë”© ë° PIL ë³€í™˜
                image_data = base64.b64decode(base64_data)
                image = Image.open(BytesIO(image_data))
                
                # í˜ì´ì§€ ë²ˆí˜¸ ê¸°ë°˜ íŒŒì¼ ì´ë¦„
                page_no = picture.prov[0].page_no if picture.prov else 0
                filename = f"page_{page_no}_img_{idx+1}.png"
                filepath = images_dir / filename
                
                image.save(filepath)
                saved_images.append({
                    'filepath': str(filepath),
                    'page_no': page_no,
                    'index': idx + 1
                })
                print(f"      âœ… ì´ë¯¸ì§€ ì €ì¥: {filename}")
                
        except Exception as e:
            print(f"      âŒ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨ {idx}: {e}")
    
    return saved_images

def generate_image_caption_with_vlm(image_path, openai_api_key):
    """OpenAI GPT-4oë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±"""
    
    try:
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')
        
        # OpenAI API ìš”ì²­
        headers = {
            "Authorization": f"Bearer {openai_api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "gpt-4o",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. ë¬¸ì„œì˜ ì¼ë¶€ë¼ë©´ ì–´ë–¤ ë‚´ìš©ì¸ì§€, í‘œë‚˜ ê·¸ë˜í”„ë¼ë©´ ì–´ë–¤ ì •ë³´ë¥¼ ë³´ì—¬ì£¼ëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”."
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{image_data}"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": 300
        }
        
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            caption = result['choices'][0]['message']['content']
            return caption.strip()
        else:
            print(f"      âŒ VLM API ì˜¤ë¥˜: {response.status_code} - {response.text}")
            return None
            
    except Exception as e:
        print(f"      âŒ VLM ìº¡ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def process_pdf_files():
    """data í´ë”ì˜ ëª¨ë“  PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±"""
    
    # OpenAI API í‚¤ í™•ì¸
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    # data í´ë”ì—ì„œ ëª¨ë“  PDF íŒŒì¼ ì°¾ê¸°
    pdf_files = glob.glob("data/*.pdf")
    
    if not pdf_files:
        print("âŒ data í´ë”ì—ì„œ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“„ ì´ {len(pdf_files)}ê°œì˜ PDF íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
    
    # ì¶œë ¥ í´ë” ìƒì„±
    output_dir = Path("data/parsed")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ê¸°ë³¸ ë³€í™˜ê¸° (ë§ˆí¬ë‹¤ìš´ ë³€í™˜ìš©)
    converter = DocumentConverter()
    
    successful_count = 0
    failed_count = 0
    
    for i, pdf_path in enumerate(pdf_files, 1):
        try:
            # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ì—¬ ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
            pdf_name = Path(pdf_path).stem
            pdf_output_dir = output_dir / pdf_name
            
            print(f"\n[{i}/{len(pdf_files)}] ì²˜ë¦¬ ì¤‘: {pdf_name}")
            print(f"   ğŸ“– ì½ëŠ” ì¤‘: {pdf_path}")
            
            # ë³€í™˜ ì‹œì‘ ì‹œê°„ ê¸°ë¡
            start_time = time.time()
            
            # 1. PDFë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜
            result = converter.convert(pdf_path)
            result_document = result.document.export_to_markdown()
            
            # 2. ì´ë¯¸ì§€ ì¶”ì¶œ (PDFë³„ ë””ë ‰í† ë¦¬ ìƒì„±)
            saved_images = extract_images_from_pdf(pdf_path, pdf_output_dir)
            
            # 3. ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±
            image_captions = []
            if saved_images:
                print(f"   ğŸ¤– {len(saved_images)}ê°œ ì´ë¯¸ì§€ì— ëŒ€í•œ ìº¡ì…˜ ìƒì„± ì¤‘...")
                
                for img_info in saved_images:
                    print(f"      ğŸ–¼ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘: {Path(img_info['filepath']).name}")
                    
                    caption = generate_image_caption_with_vlm(
                        img_info['filepath'], 
                        openai_api_key
                    )
                    
                    if caption:
                        image_captions.append({
                            'page': img_info['page_no'],
                            'image': Path(img_info['filepath']).name,
                            'caption': caption
                        })
                        print(f"      âœ… ìº¡ì…˜ ìƒì„± ì™„ë£Œ")
                    else:
                        print(f"      âŒ ìº¡ì…˜ ìƒì„± ì‹¤íŒ¨")
            
            # 4. ë§ˆí¬ë‹¤ìš´ì— ì´ë¯¸ì§€ ìº¡ì…˜ ì¶”ê°€
            if image_captions:
                result_document += "\n\n## ì´ë¯¸ì§€ ìº¡ì…˜\n\n"
                for caption_info in image_captions:
                    result_document += f"### í˜ì´ì§€ {caption_info['page']} - {caption_info['image']}\n\n"
                    result_document += f"{caption_info['caption']}\n\n"
                    result_document += "---\n\n"
            
            # 5. ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥
            output_path = output_dir / f"{pdf_name}.md"
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(result_document)
            
            # 6. ì´ë¯¸ì§€ ìº¡ì…˜ ì •ë³´ë¥¼ JSONìœ¼ë¡œë„ ì €ì¥
            if image_captions:
                captions_path = output_dir / f"{pdf_name}_captions.json"
                with open(captions_path, 'w', encoding='utf-8') as f:
                    json.dump(image_captions, f, ensure_ascii=False, indent=2)
                print(f"   ğŸ’¾ ìº¡ì…˜ ì •ë³´ ì €ì¥: {captions_path}")
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            elapsed_time = time.time() - start_time
            
            print(f"   âœ… ì™„ë£Œ: {output_path} ({elapsed_time:.2f}ì´ˆ)")
            print(f"    í†µê³„: ì´ë¯¸ì§€ {len(saved_images)}ê°œ, ìº¡ì…˜ {len(image_captions)}ê°œ")
            successful_count += 1
            
        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {pdf_name} - {str(e)}")
            failed_count += 1
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ‰ ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"   ì„±ê³µ: {successful_count}ê°œ")
    print(f"   ì‹¤íŒ¨: {failed_count}ê°œ")
    print(f"   ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_dir}")

if __name__ == "__main__":
    process_pdf_files()

